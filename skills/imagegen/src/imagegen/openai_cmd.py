"""OpenAI provider â€” ls and create commands."""

from __future__ import annotations

import base64
import json
import logging
from pathlib import Path
from typing import Optional

import typer
from openai import OpenAI
from openai.types.responses import Response

from .attachments import Attachment, load_attachment

log = logging.getLogger(__name__)

# Text models that support the image_generation tool in the Responses API.
TEXT_MODELS = [
    "gpt-4o",
    "gpt-4o-mini",
    "gpt-4.1",
    "gpt-4.1-mini",
    "gpt-4.1-nano",
    "o3",
    "gpt-5",
    "gpt-5-nano",
    "gpt-5.2",
]

# Underlying image generation models.
IMAGE_MODELS = [
    "gpt-image-1.5",
    "gpt-image-1",
    "gpt-image-1-mini",
]

app = typer.Typer(help="OpenAI image generation")


# ---------------------------------------------------------------------------
# Responses API
# ---------------------------------------------------------------------------


class OpenAIResponses:
    def __init__(
        self,
        prompt: str,
        output_path: Path,
        *,
        model: str = "gpt-5",
        image_model: str | None = None,
        size: str = "auto",
        quality: str = "auto",
        background: str = "auto",
        image_attachments: list[Attachment] | None = None,
        previous_response_id: str | None = None,
    ):
        self.prompt = prompt
        self.output_path = output_path
        self.model = model
        self.image_model = image_model
        self.size = size
        self.quality = quality
        self.background = background
        self.image_attachments = image_attachments or []
        self.previous_response_id = previous_response_id

    def _build_content(self) -> list[dict[str, str]]:
        content: list[dict[str, str]] = []
        content.append({"type": "input_text", "text": self.prompt})
        for att in self.image_attachments:
            content.append({"type": "input_image", "image_url": att.data_url})
        return content

    def _build_request(self) -> dict:  # type: ignore[type-arg]
        tool_config: dict[str, str] = {
            "type": "image_generation",
            "size": self.size,
            "quality": self.quality,
            "background": self.background,
        }
        if self.image_model:
            tool_config["model"] = self.image_model

        req: dict = {  # type: ignore[type-arg]
            "model": self.model,
            "input": [{"role": "user", "content": self._build_content()}],
            "tools": [tool_config],
        }
        if self.previous_response_id:
            req["previous_response_id"] = self.previous_response_id
        return req

    def _extract_image(self, response: Response) -> bytes:
        for output in response.output:
            if output.type == "image_generation_call":
                return base64.b64decode(output.result)  # type: ignore[arg-type]
        raise RuntimeError("No image_generation_call found in response output")

    def _save_sidecar(self, response: Response) -> None:
        meta_path = Path(str(self.output_path) + ".imagegen.json")
        meta: dict[str, str] = {"response_id": response.id, "model": self.model}
        if self.image_model:
            meta["image_model"] = self.image_model
        meta_path.write_text(json.dumps(meta, indent=2) + "\n", encoding="utf-8")
        log.info("Saved sidecar metadata to %s", meta_path)

    def run(self) -> tuple[Path, str]:
        """Run generation. Returns (output_path, response_id)."""
        client = OpenAI()
        request = self._build_request()
        log.info(
            "Sending request model=%s image_model=%s size=%s quality=%s",
            self.model,
            self.image_model or "(auto)",
            self.size,
            self.quality,
        )
        response = client.responses.create(**request)
        image_bytes = self._extract_image(response)
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        self.output_path.write_bytes(image_bytes)
        log.info("Saved image to %s (%d bytes)", self.output_path, len(image_bytes))
        self._save_sidecar(response)
        return self.output_path, response.id


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------


def _load_previous_response_id(previous: Path) -> str:
    meta_path = Path(str(previous) + ".imagegen.json")
    if not meta_path.exists():
        raise typer.BadParameter(
            f"No sidecar metadata found at {meta_path}. "
            "The --previous image must have been generated by imagegen."
        )
    meta = json.loads(meta_path.read_text(encoding="utf-8"))
    response_id = meta.get("response_id")
    if not response_id:
        raise typer.BadParameter(f"No response_id found in {meta_path}")
    return response_id


# ---------------------------------------------------------------------------
# CLI commands
# ---------------------------------------------------------------------------


@app.command()
def ls() -> None:
    """List models that support image generation."""
    typer.echo("Text models (--model with --previous):")
    for m in TEXT_MODELS:
        typer.echo(f"  {m}")
    typer.echo("")
    typer.echo("Image models (--model):")
    for m in IMAGE_MODELS:
        typer.echo(f"  {m}")


@app.command()
def create(
    prompt: list[str] = typer.Argument(
        ..., help="Text prompt fragments (joined by newlines)"
    ),
    output: Path = typer.Option(
        ..., "--output", "-o", help="Output file path"
    ),
    attach: Optional[list[Path]] = typer.Option(
        None, "--attach", "-a",
        help="Attachments (images or text files)",
    ),
    model: str = typer.Option(
        "gpt-5", "--model", help="Text model"
    ),
    image_model: Optional[str] = typer.Option(
        None, "--image-model",
        help="Image model (e.g. gpt-image-1.5)",
    ),
    size: str = typer.Option("auto", "--size", help="Image size"),
    quality: str = typer.Option(
        "auto", "--quality",
        help="Quality: low / medium / high / auto",
    ),
    background: str = typer.Option(
        "auto", "--background",
        help="Background: transparent / opaque / auto",
    ),
    previous: Optional[Path] = typer.Option(
        None, "--previous",
        help="Previous image for multi-turn editing",
    ),
) -> None:
    """Generate an image via the Responses API."""
    text_parts = list(prompt)
    image_attachments: list[Attachment] = []

    for path in attach or []:
        att = load_attachment(path)
        if att.is_image:
            image_attachments.append(att)
        else:
            text_parts.append(att.data)

    full_prompt = "\n".join(text_parts)

    previous_response_id: str | None = None
    if previous:
        previous_response_id = _load_previous_response_id(previous)
        log.info(
            "Continuing from previous response: %s",
            previous_response_id,
        )

    gen = OpenAIResponses(
        prompt=full_prompt,
        output_path=output,
        model=model,
        image_model=image_model,
        size=size,
        quality=quality,
        background=background,
        image_attachments=image_attachments,
        previous_response_id=previous_response_id,
    )
    result_path, response_id = gen.run()
    typer.echo(result_path)
    typer.echo(f"response_id: {response_id}", err=True)
